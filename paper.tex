\documentclass[english,listof=totoc]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[authoryear]{natbib}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 0},pdfborderstyle={},backref=false,colorlinks=false]
 {hyperref}\usepackage{mathtools}

\title{ML Estimation of Matrix--$t$ Distributions with Expectation Maximization}


\author{Zahari Kassabov\thanks{TIF-UNIMI-2016-5}\\
        Dipartimento di Fisica, Universit\`a di Torino and INFN, Sezione di Torino\\
		TIF Lab, Dipartimento di Fisica, Universit\`a di Milano\\
        \texttt{kassabov@to.infn.it}\\
        \and
        Hsien-Ching Kao\\
        Wolfram Research, Inc.\\
		Champaign, Illinois 61820, USA\\
		\texttt{sp000088@gmail.com}
		}

\begin{document}

\maketitle

\begin{abstract}
We provide an expectation-maximization (EM) formulae for the maximum likelihood estimation of matrix--$t$ distributions and discuss their practical implementation. The result can be applied to problems where the parameters of a matrix--$t$ distribution need to be obtained from data, such as the design of recommendation systems and remote sensing algorithms.
\end{abstract}

\section{Introduction}
Matrix--$t$ distribution is a generalization of multivariate $t$ distribution to matrix variates situations. Similar as other $t$ distributions, matrix--$t$ distribution is a scale mixture of a particular class of multivariate normal models, matrix normal distributions, except the mixture parameter is a matrix rather than a scalar \citep{gupta1999matrix}. Due to this, the distribution shares the importance in robust estimation and has been applied to many predictive tasks such as spatial interpolation on the prediction of pollution concentration \citep{KIBRIA2006785}, recommendation systems \citep{NIPS2007_3203}, and ... In these problems, it is necessary to obtain the parameters of the distribution, which consist of a degrees of freedom parameter, a matrix location parameter, and two scale matrix parameters, that describe a set of given matrix--valued observations for further inference.

A common approach on estimating the parameters is through the method of maximum likelihood (ML). However, optimizing the likelihood directly is a formidable task as the gradient equations are unwieldy slow to compute and solve. For $t$ distributions, it is well-known that one can exploit the property of scale mixture and apply expectation maximization (EM) technique to optimize the likelihood function \citep{10.2307/24305551}. The same trick can be also applied to matrix--$t$ distribution by viewing it as a matrix-normal distribution with inverse Wishart distributed scale parameter.

This note is organized as follows. In section \ref{sec:derivation}, we present an EM formulae for MLE of matrix--$t$ distribution together with the relevant details on the derivation. The notation and the preliminary results on matrix calculus needed to present the derivation are presented sequentially in the section. Practical implementation of the algorithm is discussed in section \ref{sec:implement} and a brief conclusion is given in section \ref{sec:conclusion}.

\section{EM formulae for matrix--$t$ distribution}\label{sec:derivation}

All matrices referred in this note are real. For notation convenience, the matrix determinant is denoted as $|\cdot|$ and $\left\{S_p\succ 0\right\}$ is used to indicate the set of symmetric positive definite (SPD) matrices of dimension $p$. The multivariate gamma
function, $\Gamma_{p}(\cdot)$, given in terms of the standard gamma function $\Gamma(\cdot)$ has the form
\begin{equation}
\Gamma_{p}(x)=\pi^{p(p-1)/4}\prod_{j=1}^{p}\Gamma\left(x+\frac{1-j}{2}\right).\label{eq:multgammadef}
\end{equation}
We also define the multivariate digamma function
%
\begin{equation}
\psi_{p}(x):=\frac{\partial}{\partial x}\log\Gamma_{p}(x)=\sum_{j=1}^{p}\psi\left(x+\frac{1-j}{2}\right).
\end{equation}

We first review some basic definitions on matrix--$t$ distributions. A matrix--$t$ distribution $T_{p,m}(M,\Sigma,\Omega,\nu)$ of dimensions $p\times m$ is specified by 4 parameters: the location matrix $M$ of dimensions $p\times m$ , the row and column SPD scale matrices $\Sigma$ and $\Omega$ of dimensions $p\times p$ and $m\times m$, respectively, and the degrees of freedom parameter $\nu>0$. A $p \times m$ random matrix $T$ is said to be matrix--$t$ distributed $T_{p,m}(M,\Sigma,\Omega,\nu)$ with location parameter $M$ if given the scale parameter $S$, a SPD matrix of dimensions $p\times p$, the random matrix $T$ is matrix normal distributed $N_{p,m}(M,S,\Omega)$ and $S$ is itself inverse Wishart distributed $W^{-1}(\Sigma,\nu +p -1)$:
\begin{equation}
T|M,\Sigma,\Omega,\nu,S \sim N_{p,m}(M,S,\Omega)\label{eq:tdef1}
\end{equation}
and
\begin{equation}
S|\Sigma,\nu \sim W^{-1}(\Sigma,\nu+p-1).\label{eq:tdef2}
\end{equation}

The matrix normal distribution $N_{p,m}(M,S,\Omega)$ has density
\begin{equation}
\frac{1}{(2\pi)^{pm/2}|\Omega|^{p/2}|S|^{m/2}}\exp\left(-\frac{1}{2}\textrm{tr}\left[\Omega^{-1}(X-M)^{\textrm{t}}S^{-1}(X-M)\right]\right)\label{eq:ndistpdf}
\end{equation}
at $X$ while the inverse Wishart distribution $W^{-1}(\Sigma,n)$ with $n>p-1$ has density
\begin{equation}
\frac{|\Sigma|^{\frac{n}{2}}}{2^{\frac{n p}{2}}|S|^{\frac{n+p+1}{2}}\Gamma_{p}(\frac{n}{2})}\exp\left(-\frac{1}{2}\textrm{tr}\left[\Sigma S^{-1}\right]\right)\label{eq:wdistpdf}
\end{equation}
at $S$. Here $\Gamma_{p}(\cdot)$ is the
multivariate gamma function defined in Eq.~\eqref{eq:multgammadef}.

Follow the definition in Eqs.~\eqref{eq:tdef1} and \eqref{eq:tdef2} and the densities given above we can see the density function $f(T;\left\{M,\Sigma,\Omega,\nu\right\})$ of a matrix--$t$ distribution $T_{p,m}(M,\Sigma,\Omega,\nu)$ satisfies
\begin{equation}
\frac{\Gamma_{p}\left(\frac{p+\nu+m-1}{2}\right)}{\Gamma_{p}\left(\frac{\nu+p-1}{2}\right)\pi^{\frac{mp}{2}}|\Omega|^{\frac{p}{2}}|\Sigma|^{\frac{m}{2}}}
|I_p+\Sigma^{-1}(T-M)\Omega^{-1}(T-M)^{\textrm{t}}|^{\frac{1-m-p-\nu}{2}}
\label{eq:matrixtpdf}
\end{equation}
with $I_p$ the identity matrix of dimension $p$. The marginalization over $S$ can be obtained by using the Jacobain determinant
\begin{equation}
...
\end{equation}
and the integral identity \citep{gupta1999matrix}
\begin{equation}
\int_{\left\{S_p\succ 0\right\}}e^{-\textrm{tr}[S_pA]}|S_p|^{\alpha}\,dS_p=\Gamma_{p}\left(\alpha+\frac{1+p}{2}\right)|A|^{\alpha+\frac{1+p}{2}},\label{eq:intmultgammadef}
\end{equation}
where $A$ is a $p\times p$ nonsingular matrix.

We repeat the results here because, along the way, we will utilize several results that are useful in the derivation of the EM formulae.

We will show that the matrix
\begin{equation}
T=(S^{-\frac{1}{2}})^{t}X+M\label{eq:change}
\end{equation}
follows a matrix--$t$ distribution with degrees of freedom $n=\nu-p+1$. Here $S^{\frac{1}{2}}$ is the lower Cholesky factor of $S$, i.e., $S=S^{\frac{1}{2}}(S^{\frac{1}{2}})^t$. The Jacobian determinant of the transformation \eqref{eq:change} is
\begin{equation}
\left|\frac{\partial T}{\partial X}\right|=|S|^{-\frac{m}{2}}.\label{eq:jac}
\end{equation}
Using Eq.~\eqref{eq:ndistpdf}, Eq.~\eqref{eq:wdistpdf} and Eq.~\eqref{eq:jac} we can see the joint density of $T$ and $S$ is given as
\begin{equation}
\begin{split}j(T,S;\left\{M,\Sigma,\Omega,n\right\})=\frac{\pi^{-\frac{mp}{2}}|\Sigma|^{\frac{n+p-1}{2}}|\Omega|^{\frac{n+m-2}{2}}|S|^{\frac{m+n-2}{2}}}{2^{p\frac{n+m+p-1}{2}}\Gamma_{p}(\frac{n+p-1}{2})}\times\\
\exp\left(-\frac{1}{2}\textrm{tr}\left[S(\Sigma+(T-M)\Omega^{-1}(T-M)^{\textrm{t}}\right]\right).
\end{split}
\label{eq:jointpdf}
\end{equation}

Finally we obtain the density \eqref{eq:matrixtpdf} of the matrix--$t$ distribution
by integrating over $S$ in the above expression, using Eq.~\eqref{eq:change} and slightly
rearranging the terms. In particular noting that
$|\Sigma+(T-M)\Omega^{-1}(T-M)^{\textrm{t}}|=|\Sigma||I_p+\Sigma^{-1}(T-M)\Omega^{-1}(T-M)^{\textrm{t}}|$.

\subsection{Calculating the Expectation-maximization steps}

The expectation maximization formalism entails calculating 
\begin{equation}
E=\sum_{i=1}^{N}\frac{\int_{S\succ 0}j(T_{i},S,M,\Sigma,\Omega,n)\log j(T_{i},S,M_{t},\Sigma_{t},\Omega_{t},n_{t})\,dS}{f(T;\left\{M,\Sigma,\Omega,n\right\})},\label{eq:expdef}
\end{equation}
where $\{T_i\}_{i=1}^N$ is a dataset consists of matrix elements $T_i$ from which we wish to estimate the maximum likelihood parameters of the distribution. We omit writing explicitly the dependence of $E$ on all the parameters. The values of the new guesses are found by maximizing with respect to the parameters $\{M_{t},\Sigma_{t},\Omega_{t},n_{t}\}$.

We can split the integral in Eq.~\eqref{eq:expdef} by the terms of $\log j(T_{i},S,M_{t},\Sigma_{t},\Omega_{t},n_{t})$. Eliminating a global factor $\frac{1}{2}$ and terms which do not depend on the
maximization parameters $\{M_{t},\Sigma_{t},\Omega_{t},n_{t}\}$ we have
\begin{equation}
\begin{split}\log j(T_{i},S;\left\{M_{t},\Sigma_{t},\Omega_{t},n_{t}\right\})\sim n_{t}\log|S|+\textrm{tr}\left[S(\Sigma_{t}+(T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}})\right]\\
-n_{t}p\log2-p\log |\Omega_{t}|+(n_{t}+p-1)\log |\Sigma_{t}|-2\log\Gamma_{p}(\frac{1}{2}(n_{t}+p-1)),
\end{split}
\end{equation}
where the first two terms depend on $S$, and therefore we need to compute the corresponding integral, while for the rest, the integral is proportional to the PDF of the matrix--$t$ distribution, Eq.~\eqref{eq:matrixtpdf}.

To compute
\begin{equation}
n_{t}\int_{S\succ 0}j(T_{i},S;\left\{M,\Sigma,\Omega,n\right\})\log |S|\,dS\label{eq:firstlogpart}
\end{equation}
we note that taking the derivative with respect to $x$ in Eq.~\eqref{eq:intmultgammadef} we have
\begin{equation}
\int_{S\succ 0}e^{-\textrm{tr}\left[SA\right]}|S|^{x}\log |S|\,dS=\Gamma_{p}\left(\frac{1+p+2x}{2}\right)|A|^{\frac{1+p+2x}{2}}(\log |A|+\gamma_{p}\left(\frac{1+p+2x}{2}\right)).\label{eq:intderivative}
\end{equation}
Equation~\eqref{eq:firstlogpart} can be computed by utilizing this result directly.

In order to compute the second nontrivial log term,
\begin{equation}
\int_{S\succ 0}j\left(T_{i},S,\left\{M,\Sigma,\Omega,n\right\}\right)\textrm{tr}\left[S(\Sigma_{t}+(T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}})\right]\,dS,
\end{equation}
we note that due to the linearity of the trace the result is equivalent to solving a matrix valued integral
\begin{equation}
\textrm{tr}\left[\left(\int_{S\succ 0}j\left(T_{i},S,\left\{M,\Sigma,\Omega,n\right\}\right)S\,dS\right)(\Sigma_{t}+(T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}})\right]\,.
\end{equation}
The enclosed integral also follows from Eq.~\eqref{eq:intmultgammadef}, after taking the matrix derivative with respect to $A$. Using, for symmetric $S$
\begin{equation}
\frac{d}{dA}\det A=(\det A)A^{-1}\label{eq:detderivative}
\end{equation}
and
\begin{equation}
\frac{d}{dA}e^{\textrm{tr}SA}=(e^{\textrm{trS}A})S
\end{equation}
we have 
\begin{equation}
\int_{S\succ 0}e^{-\textrm{tr}\left[SA\right]}|S|^{x}S\,dS=-\frac{1}{2}(1+p+2x)\Gamma_{p}\left(\frac{1}{2}(1+p+2x)\right)(\det A)^{\frac{1}{2}(p+2x-1)}A^{-1}
\end{equation}
from where again, we can obtain the result by direct substitution.

Combining results of the two integrals together with adequate rearrangements we obtain the integrated form of Eq.~\eqref{eq:expdef}
\begin{equation}
\begin{split}E=\sum_{i}^{N}n_{t}\psi_{p}\left(\frac{1}{2}(m+n+p-1)\right)-2\log\Gamma_{p}\left(\frac{1}{2}(n_{t}+p-1)\right)+p\log|\Omega_{t}|^{-1}\\
-n_{t}\log|(T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}}+\Sigma|+(n_{t}+p-1)\log |\Sigma_{t}|\\
-(m+n+p-1)\textrm{tr}\left(\left((T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}}+\Sigma\right)^{-1}\left((T_{i}-M_{t})\Omega_{t}^{-1}(T_{i}-M_{t})^{\textrm{t}}+\Sigma_{t}\right)\right)
\end{split}
\label{eq:fsimp}
\end{equation}
The maximization formulae is obtained setting the derivatives of this equation to zero.

For $M_{t}$ we have:
\begin{equation}
\frac{dE}{dM_{t}}=0\Rightarrow\sum_{i}^{N}\left((T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}}+\Sigma\right)^{-1}\left(T_{i}-M_{t}\right)\Omega_{t}^{-1}=0
\end{equation}
and because $\Omega_{t}$ is nonsingular, we can obtain $M_{t}$ as
a weighted average of the input data:
\begin{equation}
M_{t}=\frac{1}{N}\sum_{i}^{N}\left((T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}}+\Sigma\right)^{-1}T_{i}=\frac{1}{N}\sum_{i}^{N}W_{i}T_{i}
\end{equation}
where we have defined the weight matrices $W_{i}$ as
\begin{equation}
W_{i}=\left((T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}}+\Sigma\right)^{-1}
\end{equation}

$\Sigma_{t}$ is given in terms of the inverse of the mean weight
by:
\begin{equation}
\Sigma_{t}=\frac{n_{t}+p-1}{n+m+p-1}\left[\frac{1}{N}\sum_{i}^{N}W_{i}\right]^{-1}
\end{equation}
Note that it depends on $n_{t}$.

For $\Omega_{t}$ we obtain:
\begin{equation}
\Omega_{t}=\frac{n+p+m-1}{p}\frac{1}{N}\sum_{i}^{N}(T_{i}-M_{t})W_{i}(T_{i}-M_{t})
\end{equation}
and for $n_{t}$, in the case where $\Sigma_{t}$ is a free parameter
that needs to be estimated, we have:
\begin{equation}
-p\log(m+n+p-1)+p\log(n_{t}+p-1)+\frac{1}{N}\sum_{i}^{N}\log|W_{i}|-\log\det\left|\frac{1}{N}\sum_{i}^{N}W_{i}\right|+\psi_{p}(\frac{1}{2}(m+n+p-1))-\psi_{p}(\frac{1}{2}(n_{t}+p-1))=0
\end{equation}
otherwise if $\Sigma_{t}=\Sigma$ is fixed and does not depend on
$n_{t}$:
\begin{equation}
\log\det\Sigma_{t}-\log\det\left(\frac{1}{N}\sum_{i}^{N}W_{i}\right)+\psi_{p}(\frac{1}{2}(m+n+p-1))-\psi_{p}(\frac{1}{2}(n_{t}+p-1))=0
\end{equation}

\section{Implementation}\label{sec:implement}

\section{Conclusion}\label{sec:conclusion}

\section*{Acknowledgement}
This work is not supported by any grant and has not been presented in any regional or international meetings.

\bibliographystyle{unsrtnat}
\bibliography{references}
\end{document}
