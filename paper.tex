\documentclass[english,listof=totoc]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[authoryear]{natbib}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=false,bookmarksopen=false,
 breaklinks=false,pdfborder={0 0 0},pdfborderstyle={},backref=false,colorlinks=false]
 {hyperref}\usepackage{mathtools}

\title{ML Estimation of Matrix--$t$ Distributions with Expectation Maximization}


\author{Zahari Kassabov\thanks{TIF-UNIMI-2016-5}\\
        Dipartimento di Fisica, Universit\`a di Torino and INFN, Sezione di Torino\\
		TIF Lab, Dipartimento di Fisica, Universit\`a di Milano\\
        \texttt{kassabov@to.infn.it}\\
        \and
        Hsien-Ching Kao\\
        Wolfram Research, Inc.\\
		Champaign, Illinois 61820, USA\\
		\texttt{sp000088@gmail.com}
		}

\begin{document}

\maketitle

\begin{abstract}
We provide an expectation-maximization (EM) formulae for the maximum likelihood estimation of matrix--$t$ distributions and discuss their practical implementation. The result can be applied to problems where the parameters of a matrix--$t$ distribution need to be obtained from data, such as the design of recommendation systems and remote sensing algorithms.
\end{abstract}

\section{Introduction}
Matrix--$t$ distribution is a generalization of multivariate $t$ distribution to matrix variates situations. Similar as other $t$ distributions, matrix--$t$ distribution is a scale mixture of a particular class of multivariate normal models, matrix normal distributions, except the mixture parameter is a matrix rather than a scalar \citep{gupta1999matrix}. Due to this, the distribution shares the importance in robust estimation and has been applied to many predictive tasks such as spatial interpolation on the prediction of pollution concentration \citep{KIBRIA2006785}, recommendation systems \citep{NIPS2007_3203}, and ... In these problems, it is necessary to obtain the parameters of the distribution, which consist of a degrees of freedom parameter, a matrix location parameter, and two scale matrix parameters, that describe a set of given matrix--valued observations for further inference.

A common approach on estimating the parameters is through the method of maximum likelihood (ML). However, optimizing the likelihood directly is a formidable task as the gradient equations are unwieldy slow to compute and solve. For $t$ distributions, it is well-known that one can exploit the property of scale mixture and apply expectation maximization (EM) technique to optimize the likelihood function \citep{10.2307/24305551}. The same trick can be also applied to matrix--$t$ distribution by viewing it as a matrix-normal distribution with inverse Wishart distributed scale parameter.

This note is organized as follows. In section \ref{sec:derivation}, we present an EM formulae for MLE of matrix--$t$ distribution together with the relevant details on the derivation. The notation and the preliminary results on matrix calculus needed to present the derivation are presented sequentially in the section. Practical implementation of the algorithm is discussed in section \ref{sec:implement} and a brief conclusion is given in section \ref{sec:conclusion}.

\section{EM formulae for matrix--$t$ distribution}\label{sec:derivation}

All matrices referred in this note are real. For notation convenience, the matrix determinant is denoted as $|\cdot|$ and $\left\{S_p\succ 0\right\}$ is used to indicate the set of symmetric positive definite (SPD) matrices of dimension $p$.

We first review some basic definitions on matrix--$t$ distributions. A matrix--$t$ distribution $T_{p,m}(M,\Sigma,\Omega,n)$ of dimensions $p\times m$ is specified by 4 parameters: the location matrix $M$ of dimensions $p\times m$ , the row and column SPD scale matrices $\Sigma$ and $\Omega$ of dimensions $p\times p$ and $m\times m$, respectively, and the degrees of freedom parameter $n>0$. A $p \times m$ random matrix $T$ is said to be matrix--$t$ distributed $T_{p,m}(M,\Sigma,\Omega,n)$ with location parameter $M$ if given the row scale parameter $S$, $T$ is matrix normal distributed 


The derivation of the EM formulae is mainly based on the integral identity \citep{gupta1999matrix}
\begin{equation}
\int_{S\succ 0}e^{-\textrm{tr}(SA)}|S|^{x}\,dS=\Gamma_{p}\left(x+\frac{1+p}{2}\right)|A|^{x+\frac{1+p}{2}}.\label{eq:intmultgammadef}
\end{equation}
Here the domain of integration is the set of real symmetric
positive definite matrices with dimension $p$, $A$ is a $p\times p$
nonsingular matrix, and $\Gamma_{p}(\cdot)$ is the multivariate gamma
function, given in terms of the standard gamma function $\Gamma(\cdot)$
by
\begin{equation}
\Gamma_{p}(a)=\pi^{p(p-1)/4}\prod_{j=1}^{p}\Gamma\left(a+\frac{1-j}{2}\right).\label{eq:multgammadef}
\end{equation}
We also define the multivariate digamma function
%
\begin{equation} \psi_{p}(a)=\frac{\partial}{\partial
	a}\log\Gamma_{p}(a)=\sum_{j=1}^{p}\psi\left(a+\frac{1-j}{2}\right).
\end{equation}

A random $p\times m$ matrix $T$ following a matrix--$t$ distribution
$T_{p,m}(M,\Sigma,\Omega,n)$ has the probability density
\begin{equation}
f(T;\left\{M,\Sigma,\Omega,n\right\})=\frac{\Gamma_{p}\left(\frac{p+n+m-1}{2}\right)}{\Gamma_{p}\left(\frac{n+p-1}{2}\right)\pi^{\frac{mp}{2}}|\Omega|^{\frac{p}{2}}|\Sigma|^{\frac{m}{2}}}
|I_p+\Sigma^{-1}(T-M)\Omega^{-1}(T-M)^{\textrm{t}}|^{\frac{1-m-p-n}{2}},
\label{eq:matrixtpdf}
\end{equation}
where $\Sigma$ and $\Omega$ are both real symmetric positive definite
matrices of dimension $p$ and $m$, respectively, $M$ is a $p\times m$
matrix that indicates the location of the distribution, and $n$ is the
number of degrees of freedom.

Following \citet{gupta1999matrix}, we begin by deriving the
probability density of the matrix--$t$ distribution starting from
a matrix normal distributed random variate $X\sim N_{p,m}(M,S,\Omega)$
with Wishart distributed row scale parameter $S \sim W_{p}\left(\Sigma,\nu\right)$ of appropriate degrees of freedom $\nu$ (independent from $X$), and marginalizing over $S$. Note that the row scale
parameter $S$ is a real symmetric positive definite matrix. We repeat the results here because, along the way, we will utilize several results that are useful in the derivation of the EM formulae.

The $p\times m$ random matrix $X \sim N_{p,m}(M,S,\Omega)$ has density
\begin{equation}
	\frac{1}{(2\pi)^{pm/2}|\Omega|^{p/2}|S|^{m/2}}\exp\left(-\frac{1}{2}\textrm{tr}\left[\Omega^{-1}(X-M)^{\textrm{t}}S^{-1}(X-M)\right]\right),\label{eq:ndistpdf}
\end{equation}
where $S$ and $\Omega$ are symmetric positive definite matrices of dimension $p$ and $m$, respectively, and $M$ (the expectation of $X$) is a $p\times m$ matrix. The matrix $S$ is proportional to the covariance of the rows of $X$ while the matrix $\Omega$ is proportional to the covariance of the columns of $X$. In turn the $p\times p$ matrix $S\sim W_{p}\left(\Sigma,\nu\right)$ has density
\begin{equation}
\frac{|S|^{\frac{\nu-p-1}{2}}}{2^{\nu p/2}|\Sigma|^{\nu/2}\Gamma_{p}(\frac{\nu}{2})}\exp\left(-\textrm{tr}\left[\Sigma^{-1}S\right]\right),\label{eq:wdistpdf}
\end{equation}
where $\Sigma$ is a $p\times p$ symmetric positive definite matrix, $\nu>p-1$
is the number of degrees of freedom, and $\Gamma_{p}$ is the
multivariate gamma function defined in Eq.~\eqref{eq:multgammadef}.

We will show that the matrix
\begin{equation}
T=(S^{-\frac{1}{2}})^{t}X+M\label{eq:change}
\end{equation}
follows a matrix--$t$ distribution with degrees of freedom $n=\nu-p+1$. Here $S^{\frac{1}{2}}$ is the lower Cholesky factor of $S$, i.e., $S=S^{\frac{1}{2}}(S^{\frac{1}{2}})^t$. The Jacobian determinant of the transformation \eqref{eq:change} is
\begin{equation}
\left|\frac{\partial T}{\partial X}\right|=|S|^{-\frac{m}{2}}.\label{eq:jac}
\end{equation}
Using Eq.~\eqref{eq:ndistpdf}, Eq.~\eqref{eq:wdistpdf} and Eq.~\eqref{eq:jac} we can see the joint density of $T$ and $S$ is given as
\begin{equation}
\begin{split}j(T,S;\left\{M,\Sigma,\Omega,n\right\})=\frac{\pi^{-\frac{mp}{2}}|\Sigma|^{\frac{n+p-1}{2}}|\Omega|^{\frac{n+m-2}{2}}|S|^{\frac{m+n-2}{2}}}{2^{p\frac{n+m+p-1}{2}}\Gamma_{p}(\frac{n+p-1}{2})}\times\\
\exp\left(-\frac{1}{2}\textrm{tr}\left[S(\Sigma+(T-M)\Omega^{-1}(T-M)^{\textrm{t}}\right]\right).
\end{split}
\label{eq:jointpdf}
\end{equation}

Finally we obtain the density \eqref{eq:matrixtpdf} of the matrix--$t$ distribution
by integrating over $S$ in the above expression, using Eq.~\eqref{eq:change} and slightly
rearranging the terms. In particular noting that
$|\Sigma+(T-M)\Omega^{-1}(T-M)^{\textrm{t}}|=|\Sigma||I_p+\Sigma^{-1}(T-M)\Omega^{-1}(T-M)^{\textrm{t}}|$.

\subsection{Calculating the Expectation-maximization steps}

The expectation maximization formalism entails calculating 
\begin{equation}
E=\sum_{i=1}^{N}\frac{\int_{S\succ 0}j(T_{i},S,M,\Sigma,\Omega,n)\log j(T_{i},S,M_{t},\Sigma_{t},\Omega_{t},n_{t})\,dS}{f(T;\left\{M,\Sigma,\Omega,n\right\})},\label{eq:expdef}
\end{equation}
where $\{T_i\}_{i=1}^N$ is a dataset consists of matrix elements $T_i$ from which we wish to estimate the maximum likelihood parameters of the distribution. We omit writing explicitly the dependence of $E$ on all the parameters. The values of the new guesses are found by maximizing with respect to the parameters $\{M_{t},\Sigma_{t},\Omega_{t},n_{t}\}$.

We can split the integral in Eq.~\eqref{eq:expdef} by the terms of $\log j(T_{i},S,M_{t},\Sigma_{t},\Omega_{t},n_{t})$. Eliminating a global factor $\frac{1}{2}$ and terms which do not depend on the
maximization parameters $\{M_{t},\Sigma_{t},\Omega_{t},n_{t}\}$ we have
\begin{equation}
\begin{split}\log j(T_{i},S;\left\{M_{t},\Sigma_{t},\Omega_{t},n_{t}\right\})\sim n_{t}\log|S|+\textrm{tr}\left[S(\Sigma_{t}+(T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}})\right]\\
-n_{t}p\log2-p\log |\Omega_{t}|+(n_{t}+p-1)\log |\Sigma_{t}|-2\log\Gamma_{p}(\frac{1}{2}(n_{t}+p-1)),
\end{split}
\end{equation}
where the first two terms depend on $S$, and therefore we need to compute the corresponding integral, while for the rest, the integral is proportional to the PDF of the matrix--$t$ distribution, Eq.~\eqref{eq:matrixtpdf}.

To compute
\begin{equation}
n_{t}\int_{S\succ 0}j(T_{i},S;\left\{M,\Sigma,\Omega,n\right\})\log |S|\,dS\label{eq:firstlogpart}
\end{equation}
we note that taking the derivative with respect to $x$ in Eq.~\eqref{eq:intmultgammadef} we have
\begin{equation}
\int_{S\succ 0}e^{-\textrm{tr}\left[SA\right]}|S|^{x}\log |S|\,dS=\Gamma_{p}\left(\frac{1+p+2x}{2}\right)|A|^{\frac{1+p+2x}{2}}(\log |A|+\gamma_{p}\left(\frac{1+p+2x}{2}\right)).\label{eq:intderivative}
\end{equation}
Equation~\eqref{eq:firstlogpart} can be computed by utilizing this result directly.

In order to compute the second nontrivial log term,
\begin{equation}
\int_{S\succ 0}j\left(T_{i},S,\left\{M,\Sigma,\Omega,n\right\}\right)\textrm{tr}\left[S(\Sigma_{t}+(T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}})\right]\,dS,
\end{equation}
we note that due to the linearity of the trace the result is equivalent to solving a matrix valued integral
\begin{equation}
\textrm{tr}\left[\left(\int_{S\succ 0}j\left(T_{i},S,\left\{M,\Sigma,\Omega,n\right\}\right)S\,dS\right)(\Sigma_{t}+(T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}})\right]\,.
\end{equation}
The enclosed integral also follows from Eq.~\eqref{eq:intmultgammadef}, after taking the matrix derivative with respect to $A$. Using, for symmetric $S$
\begin{equation}
\frac{d}{dA}\det A=(\det A)A^{-1}\label{eq:detderivative}
\end{equation}
and
\begin{equation}
\frac{d}{dA}e^{\textrm{tr}SA}=(e^{\textrm{trS}A})S
\end{equation}
we have 
\begin{equation}
\int_{S\succ 0}e^{-\textrm{tr}\left[SA\right]}|S|^{x}S\,dS=-\frac{1}{2}(1+p+2x)\Gamma_{p}\left(\frac{1}{2}(1+p+2x)\right)(\det A)^{\frac{1}{2}(p+2x-1)}A^{-1}
\end{equation}
from where again, we can obtain the result by direct substitution.

Combining results of the two integrals together with adequate rearrangements we obtain the integrated form of Eq.~\eqref{eq:expdef}
\begin{equation}
\begin{split}E=\sum_{i}^{N}n_{t}\psi_{p}\left(\frac{1}{2}(m+n+p-1)\right)-2\log\Gamma_{p}\left(\frac{1}{2}(n_{t}+p-1)\right)+p\log|\Omega_{t}|^{-1}\\
-n_{t}\log|(T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}}+\Sigma|+(n_{t}+p-1)\log |\Sigma_{t}|\\
-(m+n+p-1)\textrm{tr}\left(\left((T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}}+\Sigma\right)^{-1}\left((T_{i}-M_{t})\Omega_{t}^{-1}(T_{i}-M_{t})^{\textrm{t}}+\Sigma_{t}\right)\right)
\end{split}
\label{eq:fsimp}
\end{equation}
The maximization formulae is obtained setting the derivatives of this equation to zero.

For $M_{t}$ we have:
\begin{equation}
\frac{dE}{dM_{t}}=0\Rightarrow\sum_{i}^{N}\left((T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}}+\Sigma\right)^{-1}\left(T_{i}-M_{t}\right)\Omega_{t}^{-1}=0
\end{equation}
and because $\Omega_{t}$ is nonsingular, we can obtain $M_{t}$ as
a weighted average of the input data:
\begin{equation}
M_{t}=\frac{1}{N}\sum_{i}^{N}\left((T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}}+\Sigma\right)^{-1}T_{i}=\frac{1}{N}\sum_{i}^{N}W_{i}T_{i}
\end{equation}
where we have defined the weight matrices $W_{i}$ as
\begin{equation}
W_{i}=\left((T_{i}-M)\Omega^{-1}(T_{i}-M)^{\textrm{t}}+\Sigma\right)^{-1}
\end{equation}

$\Sigma_{t}$ is given in terms of the inverse of the mean weight
by:
\begin{equation}
\Sigma_{t}=\frac{n_{t}+p-1}{n+m+p-1}\left[\frac{1}{N}\sum_{i}^{N}W_{i}\right]^{-1}
\end{equation}
Note that it depends on $n_{t}$.

For $\Omega_{t}$ we obtain:
\begin{equation}
\Omega_{t}=\frac{n+p+m-1}{p}\frac{1}{N}\sum_{i}^{N}(T_{i}-M_{t})W_{i}(T_{i}-M_{t})
\end{equation}
and for $n_{t}$, in the case where $\Sigma_{t}$ is a free parameter
that needs to be estimated, we have:
\begin{equation}
-p\log(m+n+p-1)+p\log(n_{t}+p-1)+\frac{1}{N}\sum_{i}^{N}\log|W_{i}|-\log\det\left|\frac{1}{N}\sum_{i}^{N}W_{i}\right|+\psi_{p}(\frac{1}{2}(m+n+p-1))-\psi_{p}(\frac{1}{2}(n_{t}+p-1))=0
\end{equation}
otherwise if $\Sigma_{t}=\Sigma$ is fixed and does not depend on
$n_{t}$:
\begin{equation}
\log\det\Sigma_{t}-\log\det\left(\frac{1}{N}\sum_{i}^{N}W_{i}\right)+\psi_{p}(\frac{1}{2}(m+n+p-1))-\psi_{p}(\frac{1}{2}(n_{t}+p-1))=0
\end{equation}

\section{Implementation}\label{sec:implement}

\section{Conclusion}\label{sec:conclusion}

\section*{Acknowledgement}
This work is not supported by any grant and has not been presented in any regional or international meetings.

\bibliographystyle{unsrtnat}
\bibliography{references}
\end{document}
